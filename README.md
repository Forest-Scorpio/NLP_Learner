# NLP_LearnerğŸ”¥ğŸ”¥

<div align=center>
<img width="500" src="https://i0.wp.com/techvidvan.com/tutorials/wp-content/uploads/sites/2/2020/04/use-cases-of-NLP.jpg?fit=802%2C420&ssl=1"/>
</div>

## é¡¹ç›®ä»‹ç»ğŸ 

- æ­¤é¡¹ç›®æ˜¯æœ¬äººåœ¨å­¦ä¹ **æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€`NLP`**è¿‡ç¨‹ä¸­æ”¶é›†å’Œæ€»ç»“çš„**çŸ¥è¯†ç‚¹å’Œä»£ç å®ç°**ï¼Œä¹Ÿæ˜¯ä½œä¸ºä¸€ä¸ªç®—æ³•å·¥ç¨‹å¸ˆå¿…çŸ¥å¿…ä¼šçš„ç†è®ºåŸºç¡€çŸ¥è¯†ã€‚
- æ­¤é¡¹ç›®çš„åˆ›å»ºä¸»è¦æ˜¯ä¸ºäº†ä¿å­˜åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ä½¿ç”¨çš„ç›¸å…³èµ„æ–™ï¼Œæ–¹ä¾¿æ—¥åçš„å¤ä¹ å’ŒæŸ¥æ‰¾ã€‚

------

## æœºå™¨å­¦ä¹ ğŸ‰

- **é¡¹ç›®æŒç»­æ›´æ–°ä¸­......**

- [ã€æœºå™¨å­¦ä¹ è®­ç»ƒæµç¨‹ã€‘](https://mp.weixin.qq.com/s/tDn9_4-EFolRth87O-E4NA)ï¼šä½œè€…ç”¨æ‰‹ç»˜å›¾çš„æ–¹å¼è®²è§£äº†æœºå™¨å­¦ä¹ æ¨¡å‹æ„å»ºçš„å…¨æµç¨‹ï¼Œé€»è¾‘æ¸…æ™°ã€ç”ŸåŠ¨å½¢è±¡ã€‚

- [ã€`AI`ç®—æ³•å·¥ç¨‹å¸ˆæ‰‹å†Œã€‘](http://www.huaxiaozhuan.com/)ï¼šæœ¬ä¹¦å†…å®¹éå¸¸ä¸°å¯Œï¼ŒåŸºæœ¬æ¶µç›–äº†æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ç­‰é¢†åŸŸçš„å¾ˆå¤šé‡è¦ç†è®ºçŸ¥è¯†å’Œå®æˆ˜ç»éªŒï¼ŒåŒæ—¶ä¹Ÿä»‹ç»äº†å·¥ç¨‹åº”ç”¨ä¸­ç»å¸¸ä½¿ç”¨çš„`AI`å·¥å…·å’Œç¼–ç¨‹åº“ã€‚

### å­¦ä¹ è¯¾ç¨‹ğŸˆ

- **æå®æ¯…ã€Šæœºå™¨å­¦ä¹ ã€‹è¯¾ç¨‹**ï¼šå°å¤§æå®æ¯…è€å¸ˆçš„æœºå™¨å­¦ä¹ è¯¾ç¨‹å¯ä»¥è¯´æ˜¯æœ€å…·ä»£è¡¨æ€§çš„ä¸­æ–‡å…¬å¼€è¯¾ä¹‹ä¸€ï¼Œå·²æˆä¸ºå¤§é‡å›½å†…åˆå­¦è€…çš„é¦–é€‰ã€‚è¯¥è¯¾ç¨‹æ¶‰åŠé¢†åŸŸéå¸¸å®Œæ•´ï¼Œä»æœ‰ç›‘ç£ã€åŠç›‘ç£ã€æ— ç›‘ç£åˆ°å¼ºåŒ–å­¦ä¹ ï¼Œéƒ½ä¼šæœ‰ä»‹ç»ã€‚ [ã€è¯¾ç¨‹ä¸»é¡µã€‘](http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html) [ã€è§†é¢‘ã€‘](https://www.bilibili.com/video/BV1VE411s7Xd)

- **ææ²ã€Šæ–¯å¦ç¦2021ç§‹å­£Â·å®ç”¨æœºå™¨å­¦ä¹ ã€‹è¯¾ç¨‹**ï¼šåº”ç”¨æœºå™¨å­¦ä¹ ï¼ˆ`ML`ï¼‰æ¥å‡†ç¡®å’Œç¨³å¥åœ°è§£å†³å®é™…é—®é¢˜ï¼Œéœ€è¦çš„ä¸ä»…ä»…æ˜¯è®­ç»ƒæœ€æ–°çš„MLæ¨¡å‹ã€‚è¿™é—¨è¯¾å°†åŒæ—¶æ•™æˆç»Ÿè®¡å­¦ã€ç®—æ³•å’Œä»£ç å®ç°ã€‚ä½œä¸šå’Œæœ€åçš„é¡¹ç›®å¼ºè°ƒè§£å†³å®é™…é—®é¢˜ã€‚æˆè¯¾å¤§ç‰›åŒ…æ‹¬Google Brainé«˜çº§ç ”ç©¶ç§‘å­¦å®¶ã€AWSé«˜çº§é¦–å¸­ç§‘å­¦å®¶å’ŒAWSå‰¯æ€»è£/æ°å‡ºç§‘å­¦å®¶ã€‚ [ã€è¯¾ç¨‹ä¸»é¡µã€‘](https://c.d2l.ai/stanford-cs329p/) [ã€è§†é¢‘ã€‘](https://space.bilibili.com/1567748478/channel/collectiondetail?sid=28144)

------

## æ·±åº¦å­¦ä¹ ğŸ‘¼

- **é¡¹ç›®æŒç»­æ›´æ–°ä¸­......**

### å­¦ä¹ è¯¾ç¨‹ğŸˆ

- **ææ²ã€ŠåŠ¨æ‰‹æ·±åº¦å­¦ä¹ ã€‹è¯¾ç¨‹**ï¼šäºšé©¬é€Šèµ„æ·±é¦–å¸­ç§‘å­¦å®¶[ææ²](https://space.bilibili.com/1567748478?from=search&seid=3964477932142951372&spm_id_from=333.337.0.0)è€å¸ˆçš„åŠ¨æ‰‹æ·±åº¦å­¦ä¹ è¯¾ç¨‹ï¼Œä¸»è¦ä»‹ç»äº†æ·±åº¦å­¦ä¹ ç›¸å…³çš„åŸºç¡€çŸ¥è¯†å’Œå…¶åœ¨è®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„åº”ç”¨ã€‚ [ã€è¯¾ç¨‹ä¸»é¡µã€‘](https://d2l.ai/) [ã€è§†é¢‘ã€‘](https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358497)[ã€ä¸­æ–‡ç‰ˆã€‘](https://zh.d2l.ai/)

- **é™ˆè•´ä¾¬ã€Šåº”ç”¨æ·±åº¦å­¦ä¹ ã€‹è¯¾ç¨‹**ï¼šæœ¬è¯¾ç¨‹ä¸»è¦è®²è§£å¦‚ä½•åˆ©ç”¨æ·±åº¦å­¦ä¹ ç®—æ³•æ¥è§£å†³å„ç§å®é™…åº”ç”¨åœºæ™¯é—®é¢˜ï¼Œå­¦ç”Ÿå­¦ä¹ å¦‚ä½•ä½¿ç”¨è¿™äº›æ·±åº¦å­¦ä¹ ç®—æ³•ï¼Œä»¥åŠä¸ºä»€ä¹ˆè¦ä½¿ç”¨è¿™äº›ç®—æ³•ã€‚æœ¬è¯¾ç¨‹å¸Œæœ›å­¦ç”Ÿåœ¨è¯¾å ‚ä¸Šå­¦ä¹ ç†è®ºï¼Œå¹¶é€šè¿‡åšä½œä¸šå’Œæœ€åçš„é¡¹ç›®æ¥å­¦ä¹ å®æ–½æ–¹æ³•ã€‚ [ã€è¯¾ç¨‹ä¸»é¡µã€‘](http://dwz.date/ahbP) [ã€è§†é¢‘ã€‘](https://www.bilibili.com/video/BV19g4y1b7vx?from=search&seid=8860161030043950732)

------

### æ·±åº¦å­¦ä¹ æ¡†æ¶ğŸˆ

- [pytorch](https://github.com/lyhue1991/eat_pytorch_in_20_days)
- [tensorflow](https://github.com/lyhue1991/eat_tensorflow2_in_30_days)
- [pytorch-lightning](https://github.com/PyTorchLightning/pytorch-lightning)
- [fastai](https://github.com/fastai/fastai)

## è‡ªç„¶è¯­è¨€å¤„ç†ğŸŠ

- **é¡¹ç›®æŒç»­æ›´æ–°ä¸­......**

- [è‹å‰‘æ—çš„ç§‘å­¦ç©ºé—´](https://spaces.ac.cn/)

- [Jay Alammarçš„åšå®¢](https://jalammar.github.io/)

### å­¦ä¹ è¯¾ç¨‹ğŸˆ

- **æ–¯å¦ç¦å¤§å­¦è‡ªç„¶è¯­è¨€å¤„ç†è¯¾ç¨‹CS224N**ï¼šè¯¥è¯¾ç¨‹å‡ ä¹æ¶µç›–äº†æ‰€æœ‰NLPç›¸å…³çš„å†…å®¹ï¼Œæ¶µç›–äº†è¯ä¹‰ä¸è¯å‘é‡ã€ä¾å­˜å¥æ³•åˆ†æã€è¯­è¨€æ¨¡å‹ã€æœºå™¨ç¿»è¯‘ã€æ·±åº¦é—®ç­”ã€`subword`ä¸`Transformer`ã€`BERT`ä¸é¢„è®­ç»ƒæ¨¡å‹ã€è‡ªç„¶è¯­è¨€ç”Ÿæˆã€æŒ‡ä»£æ¶ˆè§£ã€æˆåˆ†å¥æ³•åˆ†æç­‰æ–¹é¢ã€‚ [ã€è¯¾ä»¶ã€‘](https://github.com/Forest-Scorpio/NLP_Learner/tree/master/NLP/CS224N/Lectures)  [ã€è§†é¢‘ã€‘](https://www.bilibili.com/video/BV1Eb411H7Pq) [ã€åšå®¢ã€‘](https://bitjoy.net/?s=CS224N)

### çŸ¥è¯†ç‚¹ğŸˆ

| æ¨¡å—     | å†…å®¹                                                         | è®ºæ–‡                          | åšå®¢                |
| -------- | ------------------------------------------------------------ | ---------------------------- | -------------------- |
| è¯å‘é‡ | è¯åµŒå…¥(`Word2Vec`) | [ã€A Neural Probabilistic Language Model(2003)ã€‘](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)ã€ [ã€ Distributed Representations of Words and Phrases and their Compositionality(2013)ã€‘](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) | [ã€å›¾è§£Word2vec-ENã€‘](https://jalammar.github.io/illustrated-word2vec/)ã€[ã€å›¾è§£Word2vec-ZHã€‘](https://blog.csdn.net/fengdu78/article/details/109475859) |
| è¯å‘é‡ | å­è¯åµŒå…¥(`fastText`) | [ã€ Bag of Tricks for Efficient Text Classification(2016)ã€‘](http://xxx.itp.ac.cn/pdf/1607.01759.pdf) |  |
| è¯å‘é‡ | å…¨å±€å‘é‡è¯åµŒå…¥(`GloVe`) | [ã€A Neural Probabilistic Language Model(2003)ã€‘](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)ã€ [ã€ Distributed Representations of Words and Phrases and their Compositionality(2013)ã€‘](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) |  |
| é¢„è®­ç»ƒ | `BERT` | [ã€BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding(2018)ã€‘](https://readpaper.com/paper/2963341956) | [ã€å›¾è§£BERT-ENã€‘](http://jalammar.github.io/illustrated-bert/ )ã€[ã€å›¾è§£BERT-ZHã€‘](https://zhuanlan.zhihu.com/p/266364526) |

### `NLP`ä»£ç æ¡†æ¶ğŸˆ

- [transformers](https://github.com/huggingface/transformers)
- [bert4torch](https://github.com/Tongjilibo/bert4torch)
- [ark-nlp](https://github.com/xiangking/ark-nlp)

### å®æˆ˜ğŸˆ

- [åŸºäº`Transformer`çš„`NLP`ä»»åŠ¡ä»‹ç»åŠä»£ç ](https://github.com/datawhalechina/learn-nlp-with-transformers)
